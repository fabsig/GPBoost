% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GPModel.R
\name{fit.GPModel}
\alias{fit.GPModel}
\title{Fits a \code{GPModel}}
\usage{
\method{fit}{GPModel}(gp_model, y, X = NULL, params = list(),
  fixed_effects = NULL)
}
\arguments{
\item{gp_model}{a \code{GPModel}}

\item{y}{A \code{vector} with response variable data}

\item{X}{A \code{matrix} with numeric covariate data for the 
fixed effects linear regression term (if there is one)}

\item{params}{A \code{list} with parameters for the estimation / optimization
 \itemize{
    \item{optimizer_cov: Optimizer used for estimating covariance parameters. 
    Options: "gradient_descent", "fisher_scoring", "nelder_mead", "bfgs", "adam".
    Default = "gradient_descent"}
    \item{optimizer_coef: Optimizer used for estimating linear regression coefficients, if there are any 
    (for the GPBoost algorithm there are usually none). 
    Options: "gradient_descent", "wls", "nelder_mead", "bfgs", "adam". Gradient descent steps are done simultaneously 
    with gradient descent steps for the covariance parameters. 
    "wls" refers to doing coordinate descent for the regression coefficients using weighted least squares.
    Default = "wls" for Gaussian data and "gradient_descent" for other likelihoods.
    If 'optimizer_cov' is set to "nelder_mead", "bfgs", or "adam", 'optimizer_coef' is automatically also set to the same value.}
    \item{maxit: Maximal number of iterations for optimization algorithm. Default = 1000}
    \item{delta_rel_conv: Convergence tolerance. The algorithm stops if the relative change 
    in eiher the (approximate) log-likelihood or the parameters is below this value. 
    For "bfgs" and "adam", the L2 norm of the gradient is used instead of the relative change in the log-likelihood. 
    If < 0, internal default values are used. 
    Default = 1E-6 except for "nelder_mead" for which the default is 1E-8}
    \item{convergence_criterion: The convergence criterion used for terminating the optimization algorithm.
    Options: "relative_change_in_log_likelihood" (default) or "relative_change_in_parameters"}
    \item{init_coef: Initial values for the regression coefficients (if there are any, can be NULL).
    Default = NULL}
    \item{init_cov_pars: Initial values for covariance parameters of Gaussian process and 
    random effects (can be NULL). Default = NULL}
    \item{lr_coef: Learning rate for fixed effect regression coefficients if gradient descent is used.
    Default = 0.1}
    \item{lr_cov: Learning rate for covariance parameters. 
    If < 0, internal default values are used.
    Default = 0.1 for "gradient_descent" and 1. for "fisher_scoring"}
    \item{use_nesterov_acc: If TRUE Nesterov acceleration is used.
    This is used only for gradient descent. Default = TRUE}
    \item{acc_rate_coef: Acceleration rate for regression coefficients (if there are any) 
    for Nesterov acceleration. Default = 0.5}
    \item{acc_rate_cov: Acceleration rate for covariance parameters for Nesterov acceleration.
    Default = 0.5}
    \item{momentum_offset: Number of iterations for which no momentum is applied in the beginning.
    Default = 2}
    \item{trace: If TRUE, information on the progress of the parameter
    optimization is printed. Default = FALSE}
    \item{std_dev: If TRUE, approximate standard deviations are calculated for the covariance and linear regression parameters 
    (= square root of diagonal of the inverse Fisher information for Gaussian likelihoods and 
    square root of diagonal of a numerically approximated inverse Hessian for non-Gaussian likelihoods). 
    Default = TRUE}
    \item{init_aux_pars: Initial values for additional parameters for non-Gaussian likelihoods 
    (e.g., shape parameter of gamma likelihood). Default = NULL}
    \item{estimate_aux_pars: If TRUE, additional parameters for non-Gaussian likelihoods 
    are also estimated (e.g., shape parameter of gamma likelihood). Default = TRUE}
}}

\item{fixed_effects}{A \code{vector} of optional external fixed effects which are held fixed during training.}
}
\value{
A fitted \code{GPModel}
}
\description{
Estimates the parameters of a \code{GPModel} using maximum likelihood estimation
}
\examples{
# See https://github.com/fabsig/GPBoost/tree/master/R-package for more examples

data(GPBoost_data, package = "gpboost")
# Add intercept column
X1 <- cbind(rep(1,dim(X)[1]),X)
X_test1 <- cbind(rep(1,dim(X_test)[1]),X_test)

#--------------------Grouped random effects model: single-level random effect----------------
gp_model <- GPModel(group_data = group_data[,1], likelihood="gaussian")
fit(gp_model, y = y, X = X1, params = list(std_dev = TRUE))
summary(gp_model)
# Make predictions
pred <- predict(gp_model, group_data_pred = group_data_test[,1], 
                X_pred = X_test1, predict_var = TRUE)
pred$mu # Predicted mean
pred$var # Predicted variances
# Also predict covariance matrix
pred <- predict(gp_model, group_data_pred = group_data_test[,1], 
                X_pred = X_test1, predict_cov_mat = TRUE)
pred$mu # Predicted mean
pred$cov # Predicted covariance
 
\donttest{
#--------------------Gaussian process model----------------
gp_model <- GPModel(gp_coords = coords, cov_function = "exponential",
                    likelihood="gaussian")
fit(gp_model, y = y, X = X1, params = list(std_dev = TRUE))
summary(gp_model)
# Make predictions
pred <- predict(gp_model, gp_coords_pred = coords_test, 
                X_pred = X_test1, predict_cov_mat = TRUE)
pred$mu # Predicted (posterior) mean of GP
pred$cov # Predicted (posterior) covariance matrix of GP
}

}
\author{
Fabio Sigrist
}
