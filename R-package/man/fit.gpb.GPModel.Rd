% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gpb.GPModel.R
\name{fit.gpb.GPModel}
\alias{fit.gpb.GPModel}
\title{Fits a \code{gpb.GPModel}}
\usage{
\method{fit}{gpb.GPModel}(gp_model, y, X = NULL, std_dev = FALSE,
  params = list(optimizer_cov = "fisher_scoring", optimizer_coef = "wls",
  maxit = 1000, delta_rel_conv = 1e-06, init_coef = NULL, init_cov_pars = NULL,
  lr_coef = 0.01, lr_cov = 0.01, use_nesterov_acc = FALSE, acc_rate_coef = 0.1,
  acc_rate_cov = 0.5, nesterov_schedule_version = 0L, momentum_offset = 2L,
  trace = FALSE))
}
\arguments{
\item{gp_model}{a \code{gpb.GPModel}}

\item{y}{A \code{vector} with response variable data}

\item{X}{A \code{matrix} with covariate data for fixed effects ( = linear regression term)}

\item{std_dev}{If TRUE (asymptotic) standard deviations are calculated for all parameters}

\item{params}{A \code{list} with parameters for the model fitting / optimization
 \itemize{
    \item{optimizer_cov}{ Optimizer used for estimating covariance parameters. 
    Options: "gradient_descent" or "fisher_scoring" }
    \item{optimizer_coef}{ Optimizer used for estimating linear regression coefficients, if there are any 
    (for the GPBoost algorithm there are usually no). 
    Options: "gradient_descent" or "wls". Gradient descent steps are done simultaneously 
    with gradient descent steps for the covariance paramters. 
    "wls" refers to doing coordinate descent for the regression coefficients using weighted least squares.}
    \item{maxit}{ Maximal number of iterations for optimization algorithm}
    \item{delta_rel_conv}{ Convergence criterion: stop optimization if relative change 
    in parameters is below this value}
    \item{init_coef}{ Initial values for the regression coefficients (if there are any, can be NULL)}
    \item{init_cov_pars}{ Initial values for covariance parameters of Gaussian process and 
    random effects (can be NULL)}
    \item{lr_coef}{ Learning rate for fixed effect regression coefficients}
    \item{lr_cov}{ Learning rate for covariance parameters}
    \item{use_nesterov_acc}{ If TRUE Nesterov acceleration is used}
    \item{acc_rate_coef}{ Acceleration rate for regression coefficients (if there are any) for Nesterov acceleration}
    \item{acc_rate_cov}{ Acceleration rate for covariance parameters for Nesterov acceleration}
    \item{momentum_offset}{ Number of iterations for which no mometum is applied in the beginning}
    \item{trace}{ If TRUE, the value of the gradient is printed for some iterations.
    Useful for finding good learning rates.}
}}
}
\value{
A fitted gpb.GPModel
}
\description{
Estimates the parameters of a \code{gpb.GPModel} using maximum likelihood estimation
}
\examples{
## SEE ALSO THE HELP OF 'fitGPModel' FOR MORE EXAMPLES
library(gpboost)

#--------------------Grouped random effects model: single-level random effect----------------
n <- 100 # number of samples
m <- 25 # number of categories / levels for grouping variable
group <- rep(1,n) # grouping variable
for(i in 1:m) group[((i-1)*n/m+1):(i*n/m)] <- i
# Create random effects model
gp_model <- GPModel(group_data = group)

# Simulate data
sigma2_1 <- 1^2 # random effect variance
sigma2 <- 0.5^2 # error variance
 # incidence matrix relating grouped random effects to samples
Z1 <- model.matrix(rep(1,n) ~ factor(group) - 1)
set.seed(1)
b1 <- sqrt(sigma2_1) * rnorm(m) # simulate random effects
eps <- Z1 \%*\% b1
xi <- sqrt(sigma2) * rnorm(n) # simulate error term
y <- eps + xi # observed data
# Fit model
fit(gp_model, y = y, std_dev = TRUE)
summary(gp_model)
# Alternatively, define and fit model directly using fitGPModel
gp_model <- fitGPModel(group_data = group, y = y, std_dev = TRUE)
summary(gp_model)

# Make predictions
group_test <- 1:m
pred <- predict(gp_model, group_data_pred = group_test)
# Compare true and predicted random effects
plot(b1, pred$mu, xlab="truth", ylab="predicted",
     main="Comparison of true and predicted random effects")
abline(a=0,b=1)


#--------------------Gaussian process model----------------
\dontrun{
n <- 200 # number of samples
set.seed(1)
coords <- cbind(runif(n),runif(n)) # locations (=features) for Gaussian process
# Create Gaussian process model
gp_model <- GPModel(gp_coords = coords, cov_function = "exponential")
## Other covariance functions:
# gp_model <- GPModel(gp_coords = coords, cov_function = "gaussian")
# gp_model <- GPModel(gp_coords = coords,
#                     cov_function = "matern", cov_fct_shape=1.5)
# gp_model <- GPModel(gp_coords = coords,
#                     cov_function = "powered_exponential", cov_fct_shape=1.1)
# Simulate data
sigma2_1 <- 1^2 # marginal variance of GP
rho <- 0.1 # range parameter
sigma2 <- 0.5^2 # error variance
D <- as.matrix(dist(coords))
Sigma = sigma2_1*exp(-D/rho)+diag(1E-20,n)
C = t(chol(Sigma))
b_1=rnorm(n) # simulate random effect
eps <- C \%*\% b_1
xi <- sqrt(sigma2) * rnorm(n) # simulate error term
y <- eps + xi
# Fit model
fit(gp_model, y = y, std_dev = TRUE,
    params = list(optimizer_cov = "gradient_descent",
                  lr_cov = 0.1))
summary(gp_model)
# Alternatively, define and fit model directly using fitGPModel
gp_model <- fitGPModel(gp_coords = coords, cov_function = "exponential",
                        y = y, std_dev = TRUE,
                        params = list(optimizer_cov = "gradient_descent",
                                      lr_cov = 0.1))
summary(gp_model)

# Make predictions
set.seed(1)
ntest <- 5
# prediction locations (=features) for Gaussian process
coords_test <- cbind(runif(ntest),runif(ntest))/10
pred <- predict(gp_model, gp_coords_pred = coords_test,
                predict_cov_mat = TRUE)
print("Predicted (posterior/conditional) mean of GP")
pred$mu
print("Predicted (posterior/conditional) covariance matrix of GP")
pred$cov
}

}
